{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def is_terminal(token):\n",
    "    \"\"\"\n",
    "    Returns `True` unless the first character of the token is underscore.\n",
    "    \"\"\"\n",
    "    # we can take index of strings just like lists - so here, if the first\n",
    "    # character of a string is different from underscore then this function\n",
    "    # returns True\n",
    "    return token[0] != \"_\"\n",
    "\n",
    "\n",
    "def expand(grammar, tokens):\n",
    "    \"\"\"\n",
    "    Recursive function that gets a non-terminal token and replaces it with\n",
    "    other tokens.\n",
    "    \"\"\"\n",
    "    for i, token in enumerate(tokens):\n",
    "        # skip over terminals\n",
    "        if is_terminal(token):\n",
    "            # if is_terminal(token) returns true then the for loop continues to\n",
    "            # the next i, token in enumerate(tokens) instead of completing the\n",
    "            # code in the loop\n",
    "            continue\n",
    "        # if we get here, we found a non-terminal token\n",
    "        # so we need to choose a replacement at random\n",
    "        # random.choice selects a random entry in a list\n",
    "        replacement = random.choice(grammar[token])\n",
    "        if is_terminal(replacement):\n",
    "            # if the selected replacement is a proper word it just overwrites\n",
    "            # the same position in the list (if the replacement was selected\n",
    "            # from _N, _A, _P, or _V)\n",
    "            tokens[i] = replacement\n",
    "        else:\n",
    "            # if we get one of the tokens that don't terminate then we make\n",
    "            # more tokens and put them in place of the old token\n",
    "            tokens = tokens[:i] + replacement.split() + tokens[(i + 1):]\n",
    "\n",
    "        # now call expand on the new list of tokens\n",
    "        # this is a recursive call - expand calls itself but with a modified\n",
    "        # input (tokens has changed)\n",
    "        return expand(grammar, tokens)\n",
    "\n",
    "    # if we get here we had all terminals and are done\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def generate_sentence(grammar):\n",
    "    \"\"\"\n",
    "    Takes a grammar as an argument and initialises with the \"_S\" token,\n",
    "    indicating the sentence token of the grammar.\n",
    "    \"\"\"\n",
    "    return expand(grammar, [\"_S\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = {\n",
    "    # Notice that the grammar is different from the simple sentence maker\n",
    "    # The structures and substructures are strings that get split to lists in the function\n",
    "    \"_S\": [\"_NP _VP\"],\n",
    "    \"_NP\": [\"_N\",\n",
    "            \"_A _N _P _A _N\"],\n",
    "    \"_VP\": [\"_V\",\n",
    "            \"_V _NP\"],\n",
    "    \"_N\": [\"developer\", \"teacher\", \"student\"],\n",
    "    \"_A\": [\"smart\", \"interesting\", \"nice\", \"desperate\", \"annoying\"],\n",
    "    \"_P\": [\"next to\", \"near\", \"opposite\"],\n",
    "    \"_V\": [\"teaches\", \"trains\", \"tests\", \"is\", \"studies\", \"asks\"]\n",
    "    \n",
    "}\n",
    "\n",
    "# string.join(iterable) makes a new string of each element of the\n",
    "# iterable, separated by whatever string is\n",
    "print(' '.join(generate_sentence(grammar)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
